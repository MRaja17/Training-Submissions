{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0700232",
   "metadata": {},
   "source": [
    "# Hard 1 — Optimize Pandas Workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cdba36",
   "metadata": {},
   "source": [
    "We'll compare row‑wise `apply` vs vectorization, and reduce memory by downcasting dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "n = 100_000  # modest for execution; scale up locally for deeper benchmarking\n",
    "rng = np.random.default_rng(42)\n",
    "df = pd.DataFrame({\n",
    "    \"a\": rng.integers(0, 1000, size=n),\n",
    "    \"b\": rng.integers(0, 1000, size=n),\n",
    "    \"c\": rng.random(size=n)\n",
    "})\n",
    "\n",
    "def timeit(fn, *args, **kwargs):\n",
    "    t0 = time.time()\n",
    "    out = fn(*args, **kwargs)\n",
    "    t1 = time.time()\n",
    "    return out, t1 - t0\n",
    "\n",
    "# Row-wise apply (slow)\n",
    "def slow_apply(d):\n",
    "    return d.apply(lambda r: r[\"a\"] * 2 + r[\"b\"] - r[\"c\"], axis=1)\n",
    "\n",
    "# Vectorized (fast)\n",
    "def fast_vec(d):\n",
    "    return d[\"a\"] * 2 + d[\"b\"] - d[\"c\"]\n",
    "\n",
    "_, t_apply = timeit(slow_apply, df.copy())\n",
    "_, t_vec = timeit(fast_vec, df.copy())\n",
    "\n",
    "print(f\"Row-wise apply time: {t_apply:.3f}s\")\n",
    "print(f\"Vectorized time   : {t_vec:.3f}s\")\n",
    "\n",
    "# Memory optimization via downcasting\n",
    "before = df.memory_usage(deep=True).sum()\n",
    "df_opt = df.copy()\n",
    "df_opt[\"a\"] = pd.to_numeric(df_opt[\"a\"], downcast=\"unsigned\")\n",
    "df_opt[\"b\"] = pd.to_numeric(df_opt[\"b\"], downcast=\"unsigned\")\n",
    "df_opt[\"c\"] = pd.to_numeric(df_opt[\"c\"], downcast=\"float\")\n",
    "\n",
    "after = df_opt.memory_usage(deep=True).sum()\n",
    "print(f\"Memory before: {before/1e6:.2f} MB\")\n",
    "print(f\"Memory after : {after/1e6:.2f} MB\")\n",
    "print(\"Savings      :\", f\"{(1 - after/before)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f8952",
   "metadata": {},
   "source": [
    "\n",
    "**Takeaways:**\n",
    "- Prefer vectorized arithmetic, `.where`, `.mask`, and `np.select` over row‑wise `apply`.\n",
    "- Downcast numeric dtypes and convert repeated strings to `category` to cut memory.\n",
    "- Use `.assign`, `.eval`, `.query` for concise, sometimes faster expressions.\n",
    "- Chunk large CSVs (`chunksize=`) and consider Parquet for faster IO.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
